{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Install helmet-assignment helper code\n",
    "# !pip install input/helmet-assignment-helpers/helmet-assignment-main/ > /dev/null 2>&1\n",
    "from helmet_assignment.score import NFLAssignmentScorer, check_submission\n",
    "from helmet_assignment.features import add_track_features\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import itertools\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "random.seed(42)\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import sys\n",
    "sys.path.append('input/easydict-master/easydict-master/')\n",
    "# https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\n",
    "sys.path.append('input/yolov5-deepsort-pytorch/Yolov5_DeepSort_Pytorch-master/Yolov5_DeepSort_Pytorch-master/deep_sort_pytorch/')\n",
    "from deep_sort.deep_sort import DeepSort\n",
    "from utils.parser import get_config\n",
    "from helmet_assignment.video import video_with_predictions\n",
    "from IPython.display import Video, display\n",
    "\n",
    "def find_nearest(array, value): # находит значение ближайшего est_frame-а к value (фрэйму)\n",
    "    value = int(value)\n",
    "    array = np.asarray(array).astype(int)\n",
    "    idx = (np.abs(array - value)).argmin() # из номеров est_frame вычитаем frame, берем модуль. Находим индекс минимального элемента в массиве\n",
    "    return array[idx] # значение ближайшего est_frame-а\n",
    "\n",
    "def modern_posit(image_pts, world_pts, focal_length, center):\n",
    "    nb_points = np.shape(image_pts)[0]\n",
    "\n",
    "    # centered & scaled pixel coordinates\n",
    "    centered_image = np.divide(np.subtract(image_pts, center), focal_length)\n",
    "    ui = centered_image[:, 0]\n",
    "    vi = centered_image[:, 1]\n",
    "\n",
    "    # homogeneous world coordinates\n",
    "    homogeneous_world_pts = np.append(world_pts, np.ones((nb_points, 1)), 1)\n",
    "\n",
    "    # pseudo inverse\n",
    "    object_mat = np.linalg.pinv(homogeneous_world_pts)\n",
    "    #print(object_mat)\n",
    "\n",
    "    converged = 0\n",
    "    count = 0\n",
    "    t_x = 0.0\n",
    "    t_y = 0.0\n",
    "    t_z = 0.0\n",
    "    r1 = 0.0\n",
    "    r2 = 0.0\n",
    "    r3 = 0.0\n",
    "    while converged == 0:\n",
    "        # POS part of the algorithm\n",
    "        # rotation vectors\n",
    "        r1_t = np.matmul(object_mat, ui)\n",
    "        r2_t = np.matmul(object_mat, vi)\n",
    "        # 1/t_z1 is norm of r1_t\n",
    "        t_z1 = 1 / np.linalg.norm(r1_t[0:3])\n",
    "        # 1/tz_2 is norm of r2_t\n",
    "        t_z2 = 1 / np.linalg.norm(r2_t[0:3])\n",
    "        \n",
    "        # geometric average\n",
    "        t_z = np.sqrt(t_z1 * t_z2)\n",
    "        \n",
    "        r1_n = np.multiply(r1_t, t_z)\n",
    "        r2_n = np.multiply(r2_t, t_z)\n",
    "        r1 = r1_n[0:3]\n",
    "        r2 = r2_n[0:3]\n",
    "        r3 = np.cross(r1, r2)\n",
    "        r3_t = np.append(r3, t_z)\n",
    "        t_x = r1_n[3]\n",
    "        t_y = r2_n[3]\n",
    "\n",
    "        # Now update the z/T z or epsilon\n",
    "        # then ui, vi\n",
    "        epsilon_i = np.matmul(homogeneous_world_pts, np.divide(r3_t, t_z))\n",
    "        old_ui = ui\n",
    "        old_vi = vi\n",
    "        ui = np.multiply(epsilon_i, centered_image[:, 0])\n",
    "        vi = np.multiply(epsilon_i, centered_image[:, 1])\n",
    "\n",
    "        # check for convergence\n",
    "        delta_ui = ui - old_ui\n",
    "        delta_vi = vi - old_vi\n",
    "        delta = np.square(focal_length) * (np.square(np.linalg.norm(delta_ui)) + np.square(np.linalg.norm(delta_vi)))\n",
    "\n",
    "        converged = 1 if count > 0 and delta < 1 else 0\n",
    "        count = count + 1\n",
    "\n",
    "    trans = np.array([t_x, t_y, t_z], np.float64)\n",
    "    rot = np.array([r1, r2, r3], np.float64)\n",
    "    return rot, trans\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "out = pd.read_csv('tstr/out.csv')\n",
    "tracking_gp = pd.read_csv('tstr/tracking_gp.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "tracking = tracking_gp\n",
    "\n",
    "'''\n",
    "IN: результаты дипсорта с самым частым лэйблом и его значением, а также трекинг\n",
    "\n",
    "'''\n",
    "# print('out\\n',out)\n",
    "# print('tracking\\n',tracking)\n",
    "PLOT = False\n",
    "\n",
    "track_confidence = {}\n",
    "for cluster in out['deepsort_cluster'].unique(): # Пробегаемся по кластерам дипсорта\n",
    "    if not np.isnan(cluster): # Если кластер не None, то есть после пропускаемых дипсортом кадров\n",
    "        label_count = out[out['deepsort_cluster'] == cluster]['label_count_deepsort'].unique()[0] # количество появлений топ кластера\n",
    "        num_frames = len(out[out['deepsort_cluster'] == cluster]) # число кадров\n",
    "        track_confidence[cluster] = label_count/num_frames # как часто кластер появляется на кадре. Словарь Кластер:Частота\n",
    "\n",
    "out['track_confidence'] = out['deepsort_cluster'].map(track_confidence) # Добавляем столбец с conf трека\n",
    "outs_posit = []\n",
    "errors = []\n",
    "for f in [5]:#(1, out['frame'].max()+1): # пробегаемся по кадрам                \n",
    "    # результаты дипсорта сортируем по conf кластера из первого цикла и берем топ7 по conf\n",
    "    out_posit = out[out['frame'] == f].sort_values(['track_confidence'], ascending=False).copy() \n",
    "    out_posit_confident = out_posit.head(7).copy() \n",
    "    \n",
    "    # находим в треке примерный кадр и фиксируем его трек\n",
    "    nearest_frame_tracking = find_nearest(tracking['est_frame'].values, f) # int номер кадра\n",
    "    tracking_posit = tracking[tracking['est_frame']==nearest_frame_tracking].copy() # трек этого кадра\n",
    "\n",
    "    # Если игрок входит в  Топ7 из кластеров дипсорта по conf \n",
    "    tracking_posit_confident = tracking_posit[tracking_posit['player'].isin(out_posit_confident['label_deepsort'].values)].copy()\n",
    "    tracking_posit_confident['label_posit'] = tracking_posit_confident['player'].copy() # лейбл игрока\n",
    "    \n",
    "    # Находим дипсорт лэйблы у которых больше одного шлема и складываем вout_posit_confident_duplicates \n",
    "    out_posit_confident['label_posit'] = out_posit_confident['label_deepsort'].copy() # лейбл посита делаем из лейбла дипсорта\n",
    "    out_posit_confident_duplicates = out_posit_confident['label_deepsort'].value_counts() # считаем количество значений лэйблов дипсорта\n",
    "    out_posit_confident_duplicates = out_posit_confident_duplicates[out_posit_confident_duplicates > 1] # если больше 1 то складываем в датафрейм\n",
    "\n",
    "    # Разбираемся с дубликатами \n",
    "    dupl_label = \"\" # заглушка для дублируемого лэйбла\n",
    "    dupl_label_list = list(out_posit_confident_duplicates.to_dict().keys()) # делаем словарь (спиоск?) из 2+ встречающихся лэйблов дипсорта\n",
    "    if len(dupl_label_list) > 0: # список длинный\n",
    "        dupl_label = dupl_label_list[0] # оставляем первый лэйбл из списка\n",
    "\n",
    "    # Для 7 уверенных кластеров (лейблов) проставляем координаты из трека\n",
    "    out_posit_confident_merged = out_posit_confident.merge(tracking_posit_confident, on='label_posit', \n",
    "                                                           suffixes = ['','_t'])[['video_frame', 'label_posit', 'x', 'y', 'x_t', 'y_t']].copy()\n",
    "\n",
    "    # По сути дубликат 7 уверенных шлемов дипсорта\n",
    "    to_find_index = out_posit_confident.reset_index(drop=True).copy()\n",
    "\n",
    "    # Делаем двухмерные координаты из координат центров боксов. Трехмерные из координат трека плюс дополнительная зануленная координата\n",
    "    points_2d = np.array([out_posit_confident_merged['x'].values, 720-out_posit_confident_merged['y'].values]).transpose()\n",
    "    points_3d = np.array([out_posit_confident_merged['x_t'].values, out_posit_confident_merged['y_t'].values]).transpose()\n",
    "    points_3d = np.append(points_3d, np.zeros((points_3d.shape[0], 1)), axis=1)\n",
    "\n",
    "    num_of_entries = len(points_2d) # Количество шлемов в датафрейме из 7 топ шлемов (наверное их всегда <=7?)\n",
    "    # Находим список индексов где находится дубликат dupl_label \n",
    "    dupl_list = to_find_index.index[to_find_index['label_deepsort'] == dupl_label].tolist()\n",
    "    \n",
    "    best_error = float(\"inf\")\n",
    "    best_matrix = None\n",
    "    best_projected_points_2d_homogen = None\n",
    "    if (len(out_posit_confident['label_deepsort']) - len(out_posit_confident['label_deepsort'].unique()) == 1):\n",
    "        print('+++++++++++++++++++++++++++++++')\n",
    "        for idx in dupl_list:\n",
    "            points_2d = np.array([out_posit_confident_merged['x'].values, 720-out_posit_confident_merged['y'].values]).transpose()\n",
    "            points_3d = np.array([out_posit_confident_merged['x_t'].values, out_posit_confident_merged['y_t'].values]).transpose()\n",
    "            points_3d = np.append(points_3d, np.zeros((points_3d.shape[0], 1)), axis=1)\n",
    "            good_indices = list(range(num_of_entries))  # [0, 1, 2, 3, 4, 6]\n",
    "            good_indices.pop(idx)\n",
    "            points_2d = np.array([points_2d[i] for i in good_indices])\n",
    "            points_3d = np.array([points_3d[i] for i in good_indices])\n",
    "            #rot, trans = modern_posit(points_2d[indexes], points_3d[indexes], 1920, [640, 360])\n",
    "            rot, trans = modern_posit(points_2d, points_3d, 1920, [640, 360])\n",
    "            rottrans = np.append(rot, trans.reshape(3,1), axis=1)\n",
    "            intrin = np.array([\n",
    "                [1920, 0, 640],\n",
    "                [0, 1920, 360],\n",
    "                [0, 0, 1],\n",
    "            ])\n",
    "            full_matrix = np.matmul(intrin, rottrans)\n",
    "            projected_points_2d = np.matmul(full_matrix, np.transpose(np.append(points_3d, np.ones((points_3d.shape[0], 1)), axis=1)))\n",
    "            projected_points_2d_t = np.transpose(projected_points_2d)\n",
    "            projected_points_2d_homogen = projected_points_2d_t / projected_points_2d[2].reshape(points_3d.shape[0],1)\n",
    "            norm_error = np.linalg.norm(points_2d - projected_points_2d_homogen[:,0:2])\n",
    "            if norm_error < best_error:\n",
    "                best_error = norm_error\n",
    "                best_matrix = full_matrix\n",
    "                best_projected_points_2d_homogen = projected_points_2d_homogen\n",
    "        norm_error = best_error\n",
    "        full_matrix = best_matrix\n",
    "        projected_points_2d_homogen = best_projected_points_2d_homogen\n",
    "    else:\n",
    "        rot, trans = modern_posit(points_2d, points_3d, 1920, [640, 360])\n",
    "        rottrans = np.append(rot, trans.reshape(3,1), axis=1)\n",
    "        intrin = np.array([\n",
    "            [1920, 0, 640],\n",
    "            [0, 1920, 360],\n",
    "            [0, 0, 1],\n",
    "        ])\n",
    "        full_matrix = np.matmul(intrin, rottrans)\n",
    "        projected_points_2d = np.matmul(full_matrix, np.transpose(np.append(points_3d, np.ones((points_3d.shape[0], 1)), axis=1)))\n",
    "        projected_points_2d_t = np.transpose(projected_points_2d)\n",
    "        projected_points_2d_homogen = projected_points_2d_t / projected_points_2d[2].reshape(points_3d.shape[0],1)\n",
    "        norm_error = np.linalg.norm(points_2d - projected_points_2d_homogen[:,0:2])\n",
    "\n",
    "    if norm_error == float(\"inf\"):\n",
    "        norm_error = 0.0\n",
    "    #print(f, 'norm:', norm_error, f,nearest_frame_tracking, len(out_posit_confident), len(out_posit_confident['label_deepsort']) - len(out_posit_confident['label_deepsort'].unique()))\n",
    "    errors.append(norm_error)\n",
    "\n",
    "    if PLOT:\n",
    "        plt.plot(points_2d[:, 0], points_2d[:, 1], 'rx')\n",
    "        plt.plot(projected_points_2d_homogen[:, 0], projected_points_2d_homogen[:, 1], 'b.')\n",
    "        plt.axis('scaled')\n",
    "        plt.show()\n",
    "\n",
    "        x = projected_points_2d_homogen[:, 0]\n",
    "        y = projected_points_2d_homogen[:, 1]\n",
    "        labels = out_posit_confident_merged['label_posit'].values\n",
    "        labels_posit = out_posit_confident['label_posit'].values\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.set_size_inches((15, 15))\n",
    "        ax.scatter(points_2d[:, 0], points_2d[:, 1], marker='x', color='r')\n",
    "        ax.scatter(x, y, marker='.', color='b')\n",
    "        for i in range(len(x)):\n",
    "            ax.annotate(labels[i], (x[i], y[i]), color='b')\n",
    "\n",
    "        for i in range(points_2d.shape[0]):\n",
    "            ax.annotate(labels_posit[i], (points_2d[:, 0][i], points_2d[:, 1][i]), color='r')\n",
    "\n",
    "\n",
    "    points_2d_full = np.array([out_posit['x'].values, 720-out_posit['y'].values]).transpose()\n",
    "    points_3d_full = np.array([tracking_posit['x'].values, tracking_posit['y'].values]).transpose()\n",
    "    points_3d_full = np.append(points_3d_full, np.zeros((points_3d_full.shape[0], 1)), axis=1)\n",
    "\n",
    "    projected_points_2d_full = np.matmul(full_matrix, np.transpose(np.append(points_3d_full, np.ones((points_3d_full.shape[0], 1)), axis=1)))\n",
    "    projected_points_2d_t_full = np.transpose(projected_points_2d_full)\n",
    "    projected_points_2d_homogen_full = projected_points_2d_t_full / projected_points_2d_full[2].reshape(points_3d_full.shape[0],1)\n",
    "    tracking_posit[\"x_pr\"] = projected_points_2d_homogen_full[:, 0]\n",
    "    tracking_posit[\"y_pr\"] = projected_points_2d_homogen_full[:, 1]\n",
    "\n",
    "    if PLOT:\n",
    "        figure(figsize=(10,10))\n",
    "        plt.plot(points_2d_full[:, 0], points_2d_full[:, 1], 'rx')\n",
    "        plt.plot(projected_points_2d_homogen_full[:, 0], projected_points_2d_homogen_full[:, 1], 'b.')\n",
    "        plt.axis('scaled')\n",
    "        plt.show()\n",
    "\n",
    "        x = projected_points_2d_homogen_full[:, 0]\n",
    "        y = projected_points_2d_homogen_full[:, 1]\n",
    "        labels = tracking_posit['player'].values\n",
    "        labels_posit = out_posit['label'].values\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.axis('equal')\n",
    "\n",
    "        fig.set_size_inches((30, 30))\n",
    "        ax.scatter(points_2d_full[:, 0], points_2d_full[:, 1], marker='x', color='r')\n",
    "        ax.scatter(x, y, marker='.', color='b')\n",
    "        for i in range(len(x)):\n",
    "            ax.annotate(labels[i], (x[i], y[i]), color='b')\n",
    "\n",
    "        for i in range(len(labels_posit)):\n",
    "            ax.annotate(labels_posit[i], (points_2d_full[:, 0][i], points_2d_full[:, 1][i]), color='r')\n",
    "\n",
    "\n",
    "    out_posit['label_posit'] = out_posit['label_deepsort'].values.copy()\n",
    "    out_posit['y_im'] = (720 - out_posit['y']).copy()\n",
    "    indexes_to_all_distances ={}\n",
    "    for index, row in out_posit.iterrows():\n",
    "        all_distances = np.sqrt(np.square(tracking_posit['x_pr'].values - row['x']) + np.square(tracking_posit['y_pr'].values - row['y_im']))\n",
    "        all_labels = tracking_posit['player'].values \n",
    "        indexes_to_all_distances[index] = sorted(list(zip(all_labels, all_distances)), key=lambda tup: tup[1])\n",
    "\n",
    "\n",
    "    all_results = {}\n",
    "    expected_num_of_results = len(indexes_to_all_distances)\n",
    "    for _ in range(expected_num_of_results):\n",
    "        min_element = None\n",
    "        min_dist = float('inf')\n",
    "        min_label = None\n",
    "        for k, v in indexes_to_all_distances.items():\n",
    "            if v[0][1] < min_dist:\n",
    "                min_dist = v[0][1]\n",
    "                min_element = k\n",
    "                min_label = v[0][0]\n",
    "        if min_element:\n",
    "            all_results[min_element] = min_label\n",
    "        indexes_to_all_distances.pop(min_element, None)\n",
    "        for k, v in indexes_to_all_distances.items():\n",
    "            indexes_to_all_distances[k] = [t for t in v if t[0] != min_label]\n",
    "\n",
    "    for k, v in all_results.items():\n",
    "        out_posit.loc[k,'label_posit'] = v\n",
    "\n",
    "    outs_posit.append(out_posit.copy())\n",
    "\n",
    "submission_posit = pd.concat(outs_posit).copy()\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+++++++++++++++++++++++++++++++\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('Py37': conda)"
  },
  "interpreter": {
   "hash": "006033251bce7f9ca52fd59f9d14149a21f35439af3ab297784bc361980d4c46"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}