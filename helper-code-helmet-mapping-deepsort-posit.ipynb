{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.7.11 64-bit ('Py37': conda)"},"language_info":{"name":"python","version":"3.7.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"006033251bce7f9ca52fd59f9d14149a21f35439af3ab297784bc361980d4c46"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Helmet Mapping + Deepsort + Posit\n","\n","In this notebook:\n","1. I introduce a package `helmet_assignment` which includes some helper code.\n","2. I show how `deepsort` can be applied to post process exsiting predictions.\n","\n","Postprocessing is applied to the baseline predictions from [this amazing starter notebook](https://www.kaggle.com/its7171/nfl-baseline-simple-helmet-mapping).\n","\n","\n","# Helmet Mapping + Deepsort + Posit\n","\n","In this notebook:\n","1. I introduce a package `helmet_assignment` which includes some helper code.\n","2. I show how `deepsort` can be applied to post process exsiting predictions.\n","\n","Postprocessing is applied to the baseline predictions from [this amazing starter notebook](https://www.kaggle.com/its7171/nfl-baseline-simple-helmet-mapping).\n","\n","\n","\n","\n","# \"helmet_assignment\" package provides helper code.\n","\n","This package includes helpful functions like`NFLAssignmentScorer`, `check_submission` and `add_track_features`.\n","\n","- dataset: https://www.kaggle.com/robikscube/helmet-assignment-helpers\n","- github: https://github.com/RobMulla/helmet-assignment# \"helmet_assignment\" package provides helper code.\n","\n","This package includes helpful functions like`NFLAssignmentScorer`, `check_submission` and `add_track_features`.\n","\n","- dataset: https://www.kaggle.com/robikscube/helmet-assignment-helpers\n","- github: https://github.com/RobMulla/helmet-assignment\n","\n","# Baseline helmet mapping\n","This section uses the simple helmet mapping approach from the awesome notebook:\n","\n","https://www.kaggle.com/its7171/nfl-baseline-simple-helmet-mapping"],"metadata":{}},{"cell_type":"code","execution_count":2,"source":["# Install helmet-assignment helper code\n","# !pip install input/helmet-assignment-helpers/helmet-assignment-main/ > /dev/null 2>&1\n","from helmet_assignment.score import NFLAssignmentScorer, check_submission\n","from helmet_assignment.features import add_track_features\n","\n","import numpy as np\n","import pandas as pd\n","import glob\n","import os\n","import cv2\n","import itertools\n","from sklearn.metrics import accuracy_score\n","from tqdm.auto import tqdm\n","from multiprocessing import Pool\n","from matplotlib import pyplot as plt\n","from sklearn.cluster import KMeans\n","import random\n","random.seed(42)\n","from matplotlib.pyplot import figure\n","\n","# define platform\n","if os.environ['PWD'] == '/':\n","    ENTRY = 'input' # local run\n","if os.environ['PWD'] == '/kaggle/working':\n","    ENTRY = '../input' # kaggle run\n","\n","## Settings and loading data\n","n_test_videos = len(os.listdir(f'{ENTRY}/nfl-health-and-safety-helmet-assignment/test/'))\n","# Run in debug mode unless during submission\n","if n_test_videos == 6:\n","    debug = True\n","else:\n","    debug = False\n","\n","\n","\n","# Read in the data.\n","\n","BASE_DIR = f'{ENTRY}/nfl-health-and-safety-helmet-assignment'\n","\n","labels = pd.read_csv(f'{BASE_DIR}/train_labels.csv')\n","if debug:\n","    tracking = pd.read_csv(f'{BASE_DIR}/train_player_tracking.csv')\n","    helmets = pd.read_csv(f'{BASE_DIR}/train_baseline_helmets.csv')\n","else:\n","    tracking = pd.read_csv(f'{BASE_DIR}/test_player_tracking.csv')\n","    helmets = pd.read_csv(f'{BASE_DIR}/test_baseline_helmets.csv')\n","    \n","    \n","tracking = add_track_features(tracking) # add game_play, time(dt),snap, isSnap,team,snap_offset, est_frame\n","\n","def add_cols(df):\n","    df['game_play'] = df['video_frame'].str.split('_').str[:2].str.join('_')\n","    if 'video' not in df.columns:\n","        df['video'] = df['video_frame'].str.split('_').str[:3].str.join('_') + '.mp4'\n","    return df\n","\n","helmets = add_cols(helmets)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:06:23.778425Z","iopub.execute_input":"2021-10-01T10:06:23.778845Z","iopub.status.idle":"2021-10-01T10:07:14.080593Z","shell.execute_reply.started":"2021-10-01T10:06:23.778747Z","shell.execute_reply":"2021-10-01T10:07:14.079641Z"},"trusted":true}},{"cell_type":"code","execution_count":2,"source":["#  Configurables\n","n_debug_samples = 2\n","random_state = 42\n","CONF_THRE = 0.3\n","max_iter = 1000\n","DIG_STEP = 3\n","DIG_MAX = DIG_STEP*10\n","\n","if debug:\n","    helmets = add_cols(helmets)\n","    labels = add_cols(labels)\n","    # Select `n_debug_samples` worth of videos to debug with\n","#     sample_videos = labels['video'].drop_duplicates().sample(n_debug_samples, random_state=random_state).tolist()\n","    sample_videos = ['57783_003374_Endzone.mp4','57783_003374_Sideline.mp4']\n","    print('sample_videos',sample_videos)\n","    sample_gameplays = ['_'.join(x.split('_')[:2]) for x in sample_videos]\n","    print('sample_gameplays',sample_gameplays)\n","    tracking = tracking[tracking['game_play'].isin(sample_gameplays)]\n","    helmets = helmets[helmets['video'].isin(sample_videos)]\n","    labels = labels[labels['video'].isin(sample_videos)]\n","tracking.shape, helmets.shape, labels.shape"],"outputs":[{"output_type":"stream","name":"stdout","text":["sample_videos ['57783_003374_Endzone.mp4', '57783_003374_Sideline.mp4']\n","sample_gameplays ['57783_003374', '57783_003374']\n"]},{"output_type":"execute_result","data":{"text/plain":["((6424, 18), (19412, 8), (16844, 15))"]},"metadata":{},"execution_count":2}],"metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:07:14.082029Z","iopub.execute_input":"2021-10-01T10:07:14.082471Z","iopub.status.idle":"2021-10-01T10:07:23.087679Z","shell.execute_reply.started":"2021-10-01T10:07:14.082439Z","shell.execute_reply":"2021-10-01T10:07:23.086114Z"},"trusted":true}},{"cell_type":"markdown","source":["# Notebook #1"],"metadata":{}},{"cell_type":"code","execution_count":3,"source":["def find_nearest(array, value): # находит значение ближайшего est_frame-а к value (фрэйму)\n","    value = int(value)\n","    array = np.asarray(array).astype(int)\n","    idx = (np.abs(array - value)).argmin() # из номеров est_frame вычитаем frame, берем модуль. Находим индекс минимального элемента в массиве\n","    return array[idx] # значение ближайшего est_frame-а\n","\n","def norm_arr(a): # Нормируем от 0 до 1 - вычитаем из каждого значения минимальное и делим каждое значение на максимальное (после вычета)\n","    a = a-a.min()\n","    a = a/a.max()\n","    return a\n","    \n","def dist(a1, a2): \n","    '''берем разность между треком и шлемами и находим норму фробениуса \n","    (квадратный корень сумм квадратов модулей элементов матрицы размера, \n","    то есть в идеале, когда матрицы одинаковые, норма равна 0) '''\n","    return np.linalg.norm(a1-a2)\n","\n","def dist_for_different_len(a1, a2): # Передаем координату X трекинга (rotated) и центры шлемов\n","    assert len(a1) >= len(a2), f'{len(a1)}, {len(a2)}' # проверем что треков больше или равно шлемов\n","    len_diff = len(a1) - len(a2) # количество 'лишних' треков\n","    a2 = norm_arr(a2) # func 2. Передаем центры шлемов. Нормируем от 0 до 1 - вычитаем из каждого значения минимальное и делим каждое значение на максимальное (после вычета)\n","    if len_diff == 0: # Если нет 'лишних' треков\n","        a1 = norm_arr(a1) # func 2. Передаем координату Х трека. Нормируем от 0 до 1\n","        return dist(a1,a2), () # func 3. Получаем разность между треком и шлемами и находим норму фробениуса (квадратный корень сумм квадратов модулей элементов матрицы размера. Равна 0, когда матрицы одинаковые)\n","        # возвращаем значение дистанции и пустоту (тут никакие треки не выкидываем)\n","        \n","    else: # если есть \"лишние\" треки без боксов\n","        min_dist = 10000\n","        min_detete_idx = None\n","        cnt = 0\n","        del_list = list(itertools.combinations(range(len(a1)),len_diff)) # combinations(range(4), 3) --> 012 013 023 123. Координаты X трека перебираем количеством лишних треков и делаем из всех вариантов список для перебора\n","        if len(del_list) > max_iter: # если длина этого списка для перебора больше макс количества итераций\n","            del_list = random.sample(del_list, max_iter) # то берем случайный семпл размера макс количества итераций\n","        for detete_idx in del_list: # перебираем список для перебора (айдишники на удаление)\n","            this_a1 = np.delete(a1, detete_idx) # убираем 'лишние' delete_idx из массива a1. Теперь количество треков уравнивается с количеством шлемов\n","            this_a1 = norm_arr(this_a1) # func 2. Передаем сокращенные координаты Х трека. Нормируем от 0 до 1\n","            this_dist = dist(this_a1, a2) # func 3. Получаем разность между треком и шлемами и находим норму фробениуса (квадратный корень сумм квадратов модулей элементов матрицы размера. Равна 0, когда матрицы одинаковые)\n","            #print(len(a1), len(a2), this_dist)\n","            if min_dist > this_dist: # оставляем вариант с минимальной дистанцией, запоминаем айдишники треков которые нужно будет выкинуть\n","                min_dist = this_dist\n","                min_detete_idx = detete_idx\n","                \n","        return min_dist, min_detete_idx # возвращаем значение минимальной дистанции и айдишники треков которые нужно будет выкинуть\n","        \n","def rotate_arr(u, t, deg=True): \n","    '''ортогональное преобразование (всякое ортогональное преобразование является поворотом или поворотом с инверсией). \n","    Ортогональные преобразования сохраняют длины векторов и углы между векторами'''\n","    if deg == True:\n","        t = np.deg2rad(t)\n","    # при нуле [1 0][0 1] при 90 градусах [0,-1][1, 0]\n","    R = np.array([[np.cos(t), -np.sin(t)],\n","                  [np.sin(t),  np.cos(t)]])\n","    return  np.dot(R, u) # shape (2, 2) (2, 22)\n","\n","\n","def dist_rot(tracking_df, a2): # Передаем трек и координаты упорядоченных горизонтальных центров шлемов\n","    tracking_df = tracking_df.sort_values('x')\n","    x = tracking_df['x']\n","    y = tracking_df['y']\n","    min_dist = 10000\n","    min_idx = None\n","    min_x = None\n","    dig_step = 3\n","    dig_max = dig_step*10\n","    for dig in range(-dig_max,dig_max+1,dig_step):\n","        arr = rotate_arr(np.array((x,y)), dig) # func 5. Берем координаты игроков (x,y) и поворачиваем их на угол из цикла. Shape (2,22) и (x,y) и arr\n","        this_dist, this_idx = dist_for_different_len(np.sort(arr[0]), a2) # func 4. Передаем координату X трекинга (rotated) и центры шлемов\n","        if min_dist > this_dist: # оставляем минимальные дистанцию и соответствующие ей айдишники на выброс\n","            min_dist = this_dist\n","            min_idx = this_idx\n","            min_x = arr[0] # оставляем только ось X\n","    tracking_df['x_rot'] = min_x # повернутое значение X\n","    player_arr = tracking_df.sort_values('x_rot')['player'].values # сортированное повернутое значение X\n","    players = np.delete(player_arr,min_idx) # удаляем айдишники на удаление и получаем список \"обозначенных игроков\"\n","    return min_dist, players # возвращаем значение нормы и \"обозначенных игроков\"\n","\n","\n","\n","def mapping_df(args):\n","    video_frame, df = args # video_frame 57906_000718_Endzone_1, and dataframe helmets for this frame\n","\n","    gameKey,playID,view,frame = video_frame.split('_') # Разбиваем video_frame 57906_000718_Endzone_1 на четыре куска по \"_\"\n","    gameKey = int(gameKey)\n","    playID = int(playID)\n","    frame = int(frame)\n","    \n","    this_tracking = tracking[(tracking['gameKey']==gameKey) & (tracking['playID']==playID)] # отсекаем tracking для этой игры\n","    est_frame = find_nearest(this_tracking.est_frame.values, frame) # func 1 (номера 10032 кадров, из которых уникальных 456 и номер кадра). Находим ближайший кадр\n","    this_tracking = this_tracking[this_tracking['est_frame']==est_frame] # оставляем датасет ближайшего фрейма\n","    len_this_tracking = len(this_tracking) # его длина, по идее 22 (соответствует количеству игроков)\n","    \n","    # df-боксы этого кадра. Находим горизонтальные центры шлемов (положительный и отрицательный)\n","    df['center_h_p'] = (df['left']+df['width']/2).astype(int) \n","    df['center_h_m'] = (df['left']+df['width']/2).astype(int)*-1\n","    df = df[df['conf']>CONF_THRE].copy() # оставляем боксы с conf больше threshold-а\n","    if len(df) > len_this_tracking: # если боксов больше чем треков, то отсекаем лучшие боксы (количество равно количеству треков)\n","        df = df.tail(len_this_tracking)\n","    df_p = df.sort_values('center_h_p').copy() # сортируем шлемы по горизонтальным центрам от меньшего значения к большему (видимо слева направо)\n","    df_m = df.sort_values('center_h_m').copy() # сортируем шлемы по горизонтальным центрам от меньшего значения к большему, но тут для отрицательных чисел (видимо справа налево)\n","    \n","    if view == 'Endzone': # если вид вдоль поля (по ТВ обычно показывают вид поперек поля, как в футболе). То меняем местами координаты x и y\n","        this_tracking['x'], this_tracking['y'] = this_tracking['y'].copy(), this_tracking['x'].copy()\n","    a2_p = df_p['center_h_p'].values # делаем pandas series из упорядоченных горизонтальных центров положительных\n","    a2_m = df_m['center_h_m'].values # делаем pandas series из упорядоченных горизонтальных центров отрицательных\n","    \n","    min_dist_p, min_detete_idx_p = dist_rot(this_tracking ,a2_p) # func 6. Передаем трек и координаты упорядоченных горизонтальных центров шлемов полож. Возвращаем значение нормы и \"обозначенных игроков\"\n","    min_dist_m, min_detete_idx_m = dist_rot(this_tracking ,a2_m) # func 6. Передаем трек и координаты упорядоченных горизонтальных центров шлемов отриц. Возвращаем значение нормы и \"обозначенных игроков\"\n","    \n","    # оставляем из положительного и отрицательного варианта наилучший\n","    if min_dist_p < min_dist_m:\n","        min_dist = min_dist_p\n","        min_detete_idx = min_detete_idx_p\n","        tgt_df = df_p\n","    else:\n","        min_dist = min_dist_m\n","        min_detete_idx = min_detete_idx_m\n","        tgt_df = df_m\n","        \n","    #print(video_frame, len(this_tracking), len(df), len(df[df['conf']>CONF_THRE]), this_tracking['x'].mean(), min_dist_p, min_dist_m, min_dist)\n","    tgt_df['label'] = min_detete_idx # \"обозначенные игроки\"\n","    return tgt_df[['video_frame','left','width','top','height','label']]"],"outputs":[],"metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-10-01T10:07:23.090405Z","iopub.execute_input":"2021-10-01T10:07:23.090899Z","iopub.status.idle":"2021-10-01T10:07:23.119512Z","shell.execute_reply.started":"2021-10-01T10:07:23.090829Z","shell.execute_reply":"2021-10-01T10:07:23.118166Z"},"trusted":true}},{"cell_type":"code","execution_count":4,"source":["# p = Pool(processes=4)\n","# submission_df_list = []\n","# df_list = list(helmets.groupby('video_frame')) # итерируемся по кадрам 2664 штуки\n","# with tqdm(total=len(df_list)) as pbar:\n","#     for this_df in p.imap(mapping_df, df_list): # func 7\n","#         submission_df_list.append(this_df)\n","#         pbar.update(1)\n","# p.close()\n","\n","# submission_df = pd.concat(submission_df_list)\n","# submission_df.to_csv('submission-baseline.csv', index=False)\n","# submission_df = pd.read_csv('submission-baseline.csv')\n","\n","submission_df = pd.read_csv(f'{ENTRY}/baseline-seed-not-fixed/submission-baseline_57783_003374_E_and_S.csv')\n","\n","\n","## Score the predictions before applying deepsort postprocessing\n","# The scores are roughly ~0.3, which is similar to the public leaderboard.\n","if debug:\n","    scorer = NFLAssignmentScorer(labels)\n","    baseline_score = scorer.score(submission_df)\n","    print(f\"validation score {baseline_score:0.4f}\") # validation score 0.3121 # 0.2830 sample_videos ['57783_003374_Endzone.mp4', '57783_003374_Sideline.mp4']"],"outputs":[{"output_type":"stream","name":"stdout","text":["validation score 0.2830\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:07:23.121730Z","iopub.execute_input":"2021-10-01T10:07:23.122207Z","iopub.status.idle":"2021-10-01T10:07:24.015055Z","shell.execute_reply.started":"2021-10-01T10:07:23.122167Z","shell.execute_reply":"2021-10-01T10:07:24.012763Z"},"trusted":true}},{"cell_type":"markdown","source":["# Deepsort Postprocessing\n","\n","Deepsort is a popular framework for object tracking within video. \n","- [This blog post](https://nanonets.com/blog/object-tracking-deepsort/\n",") shows some examples of it being put to use.\n","- This notebook shows how to apply deepsort to this helmet dataset: https://www.kaggle.com/s903124/nfl-helmet-with-yolov5-deepsort-starter\n","- You can also read the paper for deepsort here: https://arxiv.org/pdf/1703.07402.pdf\n","\n","The approach is fairly simple:\n","1. Step through each frame in a video and apply the deepsort algorithm. This clusters helmets across frames when it is the same player/helmet.\n","2. Group by each of these deepsort clusters - and pick the most common label for that cluster. Then override all of the predictions for that helmet to the same player."],"metadata":{}},{"cell_type":"markdown","source":["## Importing Deepsort from dataset\n","Because your submission is not allowed to use internet access, you can reference the deepsort codebase from the attached dataset. Deepsort also has a dependency of `easydict` which I've also added as a dataset."],"metadata":{}},{"cell_type":"code","execution_count":5,"source":["import sys\n","sys.path.append(f'{ENTRY}/easydict-master/easydict-master/')\n","# https://github.com/mikel-brostrom/Yolov5_DeepSort_Pytorch\n","sys.path.append(f'{ENTRY}/yolov5-deepsort-pytorch/Yolov5_DeepSort_Pytorch-master/Yolov5_DeepSort_Pytorch-master/deep_sort_pytorch/')\n","from deep_sort.deep_sort import DeepSort\n","from utils.parser import get_config\n","\n","\n","\"\"\"\n","Helper functions from yolov5 to plot deepsort labels.\n","\"\"\"\n","\n","def compute_color_for_id(label):\n","    \"\"\"\n","    Simple function that adds fixed color depending on the id\n","    \"\"\"\n","    palette = (2 ** 11 - 1, 2 ** 15 - 1, 2 ** 20 - 1)\n","\n","    color = [int((p * (label ** 2 - label + 1)) % 255) for p in palette]\n","    return tuple(color)\n","\n","def plot_one_box(x, im, color=None, label=None, line_thickness=3):\n","    # Plots one bounding box on image 'im' using OpenCV\n","    assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to plot_on_box() input image.'\n","    tl = line_thickness or round(0.002 * (im.shape[0] + im.shape[1]) / 2) + 1  # line/font thickness\n","    color = color or [random.randint(0, 255) for _ in range(3)]\n","    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n","    cv2.rectangle(im, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n","    if label: \n","        tf = max(tl - 1, 1)  # font thickness\n","        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n","        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n","        cv2.rectangle(im, c1, c2, color, -1, cv2.LINE_AA)  # filled\n","        cv2.putText(im, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n","    return im"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:07:24.017753Z","iopub.execute_input":"2021-10-01T10:07:24.018497Z","iopub.status.idle":"2021-10-01T10:07:25.509982Z","shell.execute_reply.started":"2021-10-01T10:07:24.018434Z","shell.execute_reply":"2021-10-01T10:07:25.508845Z"},"trusted":true}},{"cell_type":"code","execution_count":6,"source":["%%writefile deepsort.yaml\n","\n","DEEPSORT:\n","  REID_CKPT: \"input/yolov5-deepsort-pytorch/ckpt.t7\"\n","  MAX_DIST: 0.2\n","  MIN_CONFIDENCE: 0.3\n","  NMS_MAX_OVERLAP: 0.5\n","  MAX_IOU_DISTANCE: 0.7\n","  MAX_AGE: 70\n","  N_INIT: 3\n","  NN_BUDGET: 100"],"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting deepsort.yaml\n"]}],"metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:07:25.511527Z","iopub.execute_input":"2021-10-01T10:07:25.512036Z","iopub.status.idle":"2021-10-01T10:07:25.519386Z","shell.execute_reply.started":"2021-10-01T10:07:25.511980Z","shell.execute_reply":"2021-10-01T10:07:25.517982Z"},"trusted":true}},{"cell_type":"markdown","source":["# Notebook #2 (Functions to apply deepsort to helmet boxes) & 3 (Alex)\n","\n","### Base part"],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["# Below are two functions `deepsort_helmets` which runs deepsort across a video. There is a lot of room for improving this function. \n","# The merging of deepsort labels onto the original helmet boxes is currently done in a very crude manner.\n","# `add_deepsort_label_col` mapps the most common label to each deepsort cluster.\n","\n","\n","def add_deepsort_label_col(out): # \n","    '''Даем кластеру лэйбл самого частого лэйбла. В результате добавляются label_deepsort (ИД игрока) и label_count_deepsort (число) #\n","    \n","    Input: датафрейм из deepsort_helmets - боксы, лэйблы и дипсорт кластеры\n","    Находим лэйбл, который в наибольшем количестве кадров присутствовал с определенным кластером. \n","    \n","    3. Значение наибольшего количества записываем в label_count\n","    4. Названия кластеров из индекса переходят в столбец\n","    5-6. Группируем по ним и оставляем первый (самый частый)\n","    7-1. Получаем словарь соответствия кластера и самого частого лэйбла для этого кластера\n","    7-2. Получаем словарь соответствия кластера и значения этого самого частого лэйбла\n","    '''\n","    # Find the top occuring label for each deepsort_cluster \n","\n","    sortlabel_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n","        .sort_values(ascending=False).to_frame() \\\n","        .rename(columns={'label':'label_count'}) \\\n","        .reset_index() \\\n","        .groupby(['deepsort_cluster']) \\\n","        .first()['label'].to_dict()\n","    # Find the # of times that label appears for the deepsort_cluster.\n","    sortlabelcount_map = out.groupby('deepsort_cluster')['label'].value_counts() \\\n","        .sort_values(ascending=False).to_frame() \\\n","        .rename(columns={'label':'label_count'}) \\\n","        .reset_index() \\\n","        .groupby(['deepsort_cluster']) \\\n","        .first()['label_count'].to_dict()\n","    \n","    out['label_deepsort'] = out['deepsort_cluster'].map(sortlabel_map) # the top occuring label for each deepsort_cluster\n","    out['label_count_deepsort'] = out['deepsort_cluster'].map(sortlabelcount_map) # the # of times that label appears for the deepsort_cluster.\n","\n","    return out\n","\n","def score_vs_deepsort(myvideo, out, labels):\n","    # Score the base predictions compared to the deepsort postprocessed predictions.\n","    myvideo_mp4 = myvideo + '.mp4'\n","    labels_video = labels.query('video == @myvideo_mp4')\n","    scorer = NFLAssignmentScorer(labels_video)\n","    out_deduped = out.groupby(['video_frame','label']).first().reset_index()\n","    base_video_score = scorer.score(out_deduped)\n","    \n","    out_preds = out.drop('label', axis=1).rename(columns={'label_deepsort':'label'})\n","    print(out_preds.shape)\n","    out_preds = out_preds.groupby(['video_frame','label']).first().reset_index()\n","    print(out_preds.shape)\n","    deepsort_video_score = scorer.score(out_preds)\n","    print(f'{base_video_score:0.5f} before --> {deepsort_video_score:0.5f} deepsort')\n","    \n","    \n","def score_vs_posit(myvideo, out, labels):\n","    # Score the base predictions compared to the deepsort postprocessed predictions.\n","    myvideo_mp4 = myvideo + '.mp4'\n","    labels_video = labels.query('video == @myvideo_mp4')\n","    scorer = NFLAssignmentScorer(labels_video)\n","    out_deduped = out.groupby(['video_frame','label']).first().reset_index()\n","    base_video_score = scorer.score(out_deduped)\n","    \n","    out_preds = out.drop('label', axis=1).rename(columns={'label_posit':'label'})\n","    print(out_preds.shape)\n","    out_preds = out_preds.groupby(['video_frame','label']).first().reset_index()\n","    print(out_preds.shape)\n","    deepsort_video_score = scorer.score(out_preds)\n","    print(f'{base_video_score:0.5f} before --> {deepsort_video_score:0.5f} posit')\n","    \n","    \n","def deepsort_helmets(video_data,video_dir,deepsort_config='deepsort.yaml',plot=False,plot_frames=[]):\n","    '''func1. Передаем датафрейм из submission_df, полученный из mapping_df. Путь к трейн или тест видео и фрэймы для печати'''\n","    \n","    # Setup Deepsort. Инициализируем дипсорт и потом он будет обновляться каждый кадр\n","    cfg = get_config()\n","    cfg.merge_from_file(deepsort_config)    \n","    deepsort = DeepSort(cfg.DEEPSORT.REID_CKPT,max_dist=cfg.DEEPSORT.MAX_DIST,min_confidence=cfg.DEEPSORT.MIN_CONFIDENCE,\n","                        nms_max_overlap=cfg.DEEPSORT.NMS_MAX_OVERLAP,max_iou_distance=cfg.DEEPSORT.MAX_IOU_DISTANCE,max_age=cfg.DEEPSORT.MAX_AGE,\n","                        n_init=cfg.DEEPSORT.N_INIT,nn_budget=cfg.DEEPSORT.NN_BUDGET,use_cuda=True)\n","    \n","    # Run through frames.\n","    video_data = video_data.sort_values('frame').reset_index(drop=True) # сортируем кадры по порядку \n","    ds = []\n","    # итерируемся по кадрам. Получаем датасет каждого кадра\n","    for frame, d in tqdm(video_data.groupby(['frame']), total=video_data['frame'].nunique()):  # list(video_data.groupby(['frame']))[::-1] for descenging order\n","        d['x'] = (d['left'] + round(d['width'] / 2)) # центр бокса по Х\n","        d['y'] = (d['top'] + round(d['height'] / 2)) # центр бокса по У\n","        xywhs = d[['x','y','width','height']].values # значения боксов (центры по X,Y, а также длина и ширина)\n","        cap = cv2.VideoCapture(f'{video_dir}/{myvideo}.mp4') # обращаемся к видеофайлу\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, frame-1) # Устанавливаем индекс кадра, который будет извлекаться из видеопотока (индексация начинается от 0)\n","        success, image = cap.read() # Считываем кадр(картинку) , метод возвращает флаг success (True , False) и image — саму картинку (массив numpy)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Меняем цветовое пространство на RGB\n","        confs = np.ones([len(d),]) # создаем массив единиц для confs каждого бокса этого кадра\n","        clss =  np.zeros([len(d),]) # создаем массив нулей для класса каждого бокса этого кадра\n","        # в deepsort передаем параметры боксов, confs, классы и картинку. outputs это [x1, y1, x2, y2, track_id, class_id]\n","        outputs = deepsort.update(xywhs, confs, clss, image) \n","        \n","\n","        # # отрисовка промежуточных кадров с боксами из plot_frames\n","        # if (plot and frame > cfg.DEEPSORT.N_INIT) or (frame in plot_frames): # N_INIT=3\n","        #     # print('To Deepsort:',xywhs, confs, clss, image,sep='\\n')\n","        #     # print('Outputs from Deepsort\\n',outputs)\n","        #     shown_labels = []\n","        #     for j, (output, conf) in enumerate(zip(outputs, confs)):  # outputs из deepsort-a\n","        #         # outputs это [x1, y1, x2, y2, track_id, class_id], распарсиваем\n","        #         bboxes = output[0:4]\n","        #         id = output[4]\n","        #         cls = output[5]\n","        #         c = int(cls)  # integer class\n","        #         label = f'{id}'\n","        #         shown_labels.append(label)\n","        #         color = compute_color_for_id(id)\n","        #         im = plot_one_box(bboxes, image, label=label, color=color, line_thickness=2)\n","        #     fig, ax = plt.subplots(figsize=(15, 10))\n","        #     video_frame = d['video_frame'].values[0]\n","        #     ax.set_title(f'Deepsort labels: {video_frame}, shown_labels: {shown_labels}')\n","        #     plt.imshow(im)\n","        #     plt.show()\n","\n","        # outputs из deepsort-a запаковываем в датафрейм, outputs это [x1, y1, x2, y2, track_id, class_id]\n","        preds_df = pd.DataFrame(outputs, columns=['left','top','right','bottom','deepsort_cluster','class']) #\n","        if len(preds_df) > 0:\n","            # TODO Fix this messy merge # This is similar to a left-join except that we match on nearest key. DataFrames must be sorted by the key.\n","            d = pd.merge_asof(d.sort_values(['left','top']), # исходный датафрейм этого кадра из video_data, по сути submission_df\n","                              preds_df[['left','top','deepsort_cluster']].sort_values(['left','top']), \n","                              on='left', suffixes=('','_deepsort'),direction='nearest') # Whether to search for prior, subsequent, or closest matches \n","        ds.append(d) # Складываем покадрово результаты Deepsort-a\n","    dout = pd.concat(ds)\n","    return dout"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:07:25.521381Z","iopub.execute_input":"2021-10-01T10:07:25.521857Z","iopub.status.idle":"2021-10-01T10:07:25.552318Z","shell.execute_reply.started":"2021-10-01T10:07:25.521785Z","shell.execute_reply":"2021-10-01T10:07:25.550947Z"},"trusted":true}},{"cell_type":"markdown","source":["### Posit part (Alex)"],"metadata":{}},{"cell_type":"code","execution_count":19,"source":["# Posit Part (Alex)\n","def normalize_by_two_dots(xs, ys, pivot_idx, target_idx):\n","    xs_shifted = xs - xs[pivot_idx]\n","    ys_shifted = ys - ys[pivot_idx]\n","    # plt.plot(xs, ys, 'b.')\n","    # plt.show()\n","    \n","    target_x = xs_shifted[target_idx]\n","    target_y = ys_shifted[target_idx]\n","    # plt.plot(xs_shifted, ys_shifted, 'b.')\n","    # plt.show()\n","    \n","    if target_x == 0.0:\n","        if target_y >= 0:\n","            t = np.pi/2\n","        else:\n","            t = 3*np.pi/2\n","    elif target_y == 0.0:\n","        if target_x >= 0:\n","            t = 0\n","        else:\n","            t = np.pi\n","    else:\n","        if target_x > 0 and target_y > 0:\n","            quadrant = 1\n","            tangens = abs(target_y) / abs(target_x)\n","        elif target_x < 0 and target_y > 0:\n","            quadrant = 2\n","            tangens = abs(target_x) / abs(target_y)\n","        elif target_x < 0 and target_y < 0:\n","            quadrant = 3\n","            tangens = abs(target_y) / abs(target_x)\n","        else:\n","            quadrant = 4\n","            tangens = abs(target_x) / abs(target_y)\n","         \n","        t = -(np.arctan(tangens) + (quadrant-1)*np.pi/2)\n","    R = np.array([[np.cos(t), -np.sin(t)],\n","                  [np.sin(t),  np.cos(t)]])\n","    u = np.array([xs_shifted, ys_shifted])\n","    rotated = np.dot(R, u)\n","    # print(quadrant, tangens, t)\n","    # plt.plot(rotated[0], rotated[1], 'b.')\n","    # plt.show()\n","    rotated_scaled = rotated/rotated[0][target_idx]\n","    return rotated_scaled\n","\n","def modern_posit(image_pts, world_pts, focal_length, center):\n","    nb_points = np.shape(image_pts)[0]\n","\n","    # centered & scaled pixel coordinates\n","    centered_image = np.divide(np.subtract(image_pts, center), focal_length)\n","    ui = centered_image[:, 0]\n","    vi = centered_image[:, 1]\n","\n","    # homogeneous world coordinates\n","    homogeneous_world_pts = np.append(world_pts, np.ones((nb_points, 1)), 1)\n","\n","    # pseudo inverse\n","    object_mat = np.linalg.pinv(homogeneous_world_pts)\n","    #print(object_mat)\n","\n","    converged = 0\n","    count = 0\n","    t_x = 0.0\n","    t_y = 0.0\n","    t_z = 0.0\n","    r1 = 0.0\n","    r2 = 0.0\n","    r3 = 0.0\n","    while converged == 0:\n","        # POS part of the algorithm\n","        # rotation vectors\n","        r1_t = np.matmul(object_mat, ui)\n","        r2_t = np.matmul(object_mat, vi)\n","        # 1/t_z1 is norm of r1_t\n","        t_z1 = 1 / np.linalg.norm(r1_t[0:3])\n","        # 1/tz_2 is norm of r2_t\n","        t_z2 = 1 / np.linalg.norm(r2_t[0:3])\n","        \n","        # geometric average\n","        t_z = np.sqrt(t_z1 * t_z2)\n","        \n","        r1_n = np.multiply(r1_t, t_z)\n","        r2_n = np.multiply(r2_t, t_z)\n","        r1 = r1_n[0:3]\n","        r2 = r2_n[0:3]\n","        r3 = np.cross(r1, r2)\n","        r3_t = np.append(r3, t_z)\n","        t_x = r1_n[3]\n","        t_y = r2_n[3]\n","\n","        # Now update the z/T z or epsilon\n","        # then ui, vi\n","        epsilon_i = np.matmul(homogeneous_world_pts, np.divide(r3_t, t_z))\n","        old_ui = ui\n","        old_vi = vi\n","        ui = np.multiply(epsilon_i, centered_image[:, 0])\n","        vi = np.multiply(epsilon_i, centered_image[:, 1])\n","\n","        # check for convergence\n","        delta_ui = ui - old_ui\n","        delta_vi = vi - old_vi\n","        delta = np.square(focal_length) * (np.square(np.linalg.norm(delta_ui)) + np.square(np.linalg.norm(delta_vi)))\n","\n","        converged = 1 if count > 0 and delta < 1 else 0\n","        count = count + 1\n","\n","    trans = np.array([t_x, t_y, t_z], np.float64)\n","    rot = np.array([r1, r2, r3], np.float64)\n","    return rot, trans\n","\n","def find_nearest(array, value): # находит значение ближайшего est_frame-а к value (фрэйму)\n","    value = int(value)\n","    array = np.asarray(array).astype(int)\n","    idx = (np.abs(array - value)).argmin() # из номеров est_frame вычитаем frame, берем модуль. Находим индекс минимального элемента в массиве\n","    return array[idx] # значение ближайшего est_frame-а\n","\n","def process_with_posit(out, tracking): # Posit начало. На входе результаты дипсорта и трекинг\n","    PLOT = False\n","    # Confidence block. Доля самого частого лэйбла от общего количества в заданном кластере дипсорта.\n","    track_confidence = {}\n","    for cluster in out['deepsort_cluster'].unique(): # Пробегаемся по кластерам дипсорта\n","        if not np.isnan(cluster): # Если кластер не None, то есть после пропускаемых дипсортом кадров\n","            label_count = out[out['deepsort_cluster'] == cluster]['label_count_deepsort'].unique()[0] # количество появлений топ кластера\n","            num_frames = len(out[out['deepsort_cluster'] == cluster]) # число кадров\n","            track_confidence[cluster] = label_count/num_frames # как часто кластер появляется на кадре. Словарь Кластер:Частота\n","    \n","    out['track_confidence'] = out['deepsort_cluster'].map(track_confidence) # Добавляем столбец с conf трека\n","\n","    outs_posit = []\n","    #for f in range(0, out['frame'].max(), 20):\n","    errors = []\n","    #for f in [195]:\n","    for f in range(1, out['frame'].max()+1): # пробегаемся по кадрам. Tester: for f in [5]:\n","        # результаты дипсорта сортируем по conf кластера из первого цикла и берем топ7 по conf\n","        out_posit = out[out['frame'] == f].sort_values(['track_confidence'], ascending=False).copy() \n","        out_posit_confident = out_posit.head(7).copy() \n","        \n","        # находим в треке примерный кадр и фиксируем его трек\n","        nearest_frame_tracking = find_nearest(tracking['est_frame'].values, f) # int номер кадра\n","        tracking_posit = tracking[tracking['est_frame']==nearest_frame_tracking].copy() # трек этого кадра\n","        \n","        # Если игрок входит в  Топ7 из кластеров дипсорта по conf \n","        tracking_posit_confident = tracking_posit[tracking_posit['player'].isin(out_posit_confident['label_deepsort'].values)].copy()\n","        tracking_posit_confident['label_posit'] = tracking_posit_confident['player'].copy() # лейбл игрока\n","        \n","        # Находим дипсорт лэйблы у которых больше одного шлема и складываем в out_posit_confident_duplicates \n","        out_posit_confident['label_posit'] = out_posit_confident['label_deepsort'].copy() # лейбл посита делаем из лейбла дипсорта\n","        out_posit_confident_duplicates = out_posit_confident['label_deepsort'].value_counts() # считаем количество значений лэйблов дипсорта\n","        out_posit_confident_duplicates = out_posit_confident_duplicates[out_posit_confident_duplicates > 1] # если больше 1 то складываем в датафрейм\n","\n","        # Разбираемся с дубликатами \n","        dupl_label = \"\" # заглушка для дублируемого лэйбла\n","        dupl_label_list = list(out_posit_confident_duplicates.to_dict().keys()) # делаем словарь (список?) из 2+ встречающихся лэйблов дипсорта\n","        if len(dupl_label_list) > 0: # список длинный\n","            dupl_label = dupl_label_list[0] # оставляем первый лэйбл из списка\n","\n","        # Для 7 уверенных кластеров (лейблов) проставляем координаты из трека\n","        out_posit_confident_merged = out_posit_confident.merge(tracking_posit_confident, on='label_posit', suffixes = ['','_t'])[['video_frame', 'label_posit', 'x', 'y', 'x_t', 'y_t']].copy()\n","        \n","        # По сути дубликат 7 уверенных шлемов дипсорта\n","        to_find_index = out_posit_confident.reset_index(drop=True).copy()\n","\n","        # Делаем двухмерные координаты из координат центров боксов. Трехмерные из координат трека плюс дополнительная зануленная координата\n","        points_2d = np.array([out_posit_confident_merged['x'].values, 720-out_posit_confident_merged['y'].values]).transpose()\n","        points_3d = np.array([out_posit_confident_merged['x_t'].values, out_posit_confident_merged['y_t'].values]).transpose()\n","        points_3d = np.append(points_3d, np.zeros((points_3d.shape[0], 1)), axis=1)\n","\n","        num_of_entries = len(points_2d) # Количество шлемов в датафрейме из 7 топ шлемов (наверное их всегда <=7?)\n","        # Находим список индексы где находится дубликат dupl_label \n","        dupl_list = to_find_index.index[to_find_index['label_deepsort'] == dupl_label].tolist()\n","\n","        best_error = float(\"inf\")\n","        best_matrix = None\n","        best_projected_points_2d_homogen = None\n","        # Если есть дубликаты в столбце label_deepsort, то сначала убираем дубликаты и потом Posit\n","        if (len(out_posit_confident['label_deepsort']) - len(out_posit_confident['label_deepsort'].unique()) == 1):\n","            for idx in dupl_list: # итерируемся по индексам дубликатов\n","                # Делаем двухмерные координаты из координат центров боксов. Трехмерные из координат трека плюс дополнительная зануленная координата\n","                points_2d = np.array([out_posit_confident_merged['x'].values, 720-out_posit_confident_merged['y'].values]).transpose() # (6,2)\n","                points_3d = np.array([out_posit_confident_merged['x_t'].values, out_posit_confident_merged['y_t'].values]).transpose() # (6,2)\n","                points_3d = np.append(points_3d, np.zeros((points_3d.shape[0], 1)), axis=1)  # (6,3)\n","                \n","                # выкидываем из 7 шлемов дублирующий\n","                good_indices = list(range(num_of_entries))  # [0, 1, 2, 3, 4, 6]\n","                good_indices.pop(idx)  # выкидываем итериуемый индекс\n","                points_2d = np.array([points_2d[i] for i in good_indices])\n","                points_3d = np.array([points_3d[i] for i in good_indices])\n","\n","                # Posit\n","                #rot, trans = modern_posit(points_2d[indexes], points_3d[indexes], 1920, [640, 360])\n","                rot, trans = modern_posit(points_2d, points_3d, 1920, [640, 360]) # получаем матрицу поворота и перемещения\n","                rottrans = np.append(rot, trans.reshape(3,1), axis=1)  # объединяем их в одну (3,4)\n","                intrin = np.array([\n","                    [1920, 0, 640],\n","                    [0, 1920, 360],\n","                    [0, 0, 1],])\n","                full_matrix = np.matmul(intrin, rottrans)  # применяем матрицу поворот+перемещение (векторное произведение)\n","\n","                # Векторное произведение full_matrix и трехмерныых координат трека с добавленным столбцом единиц. Результат (3,6)\n","                # Берем трехмерные координаты трека points_3d (6,3) (с добавленной нулевой третьей осью) # добавляем единичный столбец (6,4) и транспонируем\n","                projected_points_2d = np.matmul(full_matrix, np.transpose(np.append(points_3d, np.ones((points_3d.shape[0], 1)), axis=1)))\n","                \n","                projected_points_2d_t = np.transpose(projected_points_2d) # транспонируем (6,3)\n","                # Происходит магия, на выходе (6,3)\n","                projected_points_2d_homogen = projected_points_2d_t / projected_points_2d[2].reshape(points_3d.shape[0],1)\n","\n","                # Считаем ошибку и если она меньше предыдущей минимальной (или бесконечности в начале), то фиксируем norm_error, full_matrix, projected_points_2d_homogen\n","                norm_error = np.linalg.norm(points_2d - projected_points_2d_homogen[:,0:2])\n","                if norm_error < best_error:\n","                    best_error = norm_error\n","                    best_matrix = full_matrix\n","                    best_projected_points_2d_homogen = projected_points_2d_homogen\n","            # После того как проитерировали все индексы дубликатов, фиксируем norm_error, full_matrix, projected_points_2d_homogen из варианта с минимальной ошибкой\n","            norm_error = best_error\n","            full_matrix = best_matrix\n","            projected_points_2d_homogen = best_projected_points_2d_homogen\n","        # Если нет дубликатов, то просто применяем Posit\n","        else:\n","            rot, trans = modern_posit(points_2d, points_3d, 1920, [640, 360])\n","            rottrans = np.append(rot, trans.reshape(3,1), axis=1)\n","            intrin = np.array([\n","                [1920, 0, 640],\n","                [0, 1920, 360],\n","                [0, 0, 1],\n","            ])\n","            full_matrix = np.matmul(intrin, rottrans)\n","            projected_points_2d = np.matmul(full_matrix, np.transpose(np.append(points_3d, np.ones((points_3d.shape[0], 1)), axis=1)))\n","            projected_points_2d_t = np.transpose(projected_points_2d)\n","            projected_points_2d_homogen = projected_points_2d_t / projected_points_2d[2].reshape(points_3d.shape[0],1)\n","            norm_error = np.linalg.norm(points_2d - projected_points_2d_homogen[:,0:2])\n","\n","        # Если norm_error остался бесконечным, то фиксируем его 0\n","        if norm_error == float(\"inf\"):\n","            norm_error = 0.0\n","        #print(f, 'norm:', norm_error, f,nearest_frame_tracking, len(out_posit_confident), len(out_posit_confident['label_deepsort']) - len(out_posit_confident['label_deepsort'].unique()))\n","        errors.append(norm_error)\n","\n","        # Рисуем уверенные шлемы\n","        if PLOT:\n","            plt.plot(points_2d[:, 0], points_2d[:, 1], 'rx') # координаты уверенных шлемов\n","            plt.plot(projected_points_2d_homogen[:, 0], projected_points_2d_homogen[:, 1], 'b.') # Результаты преобразования трека при помощи Posit\n","            plt.axis('scaled')\n","            plt.show()\n","\n","            # ПО сути простановка индексов правильных из трека\n","            x = projected_points_2d_homogen[:, 0]\n","            y = projected_points_2d_homogen[:, 1]\n","            labels = out_posit_confident_merged['label_posit'].values\n","            labels_posit = out_posit_confident['label_posit'].values\n","            fig, ax = plt.subplots()\n","            fig.set_size_inches((15, 15))\n","            ax.scatter(points_2d[:, 0], points_2d[:, 1], marker='x', color='r')\n","            ax.scatter(x, y, marker='.', color='b')\n","            for i in range(len(x)):\n","                ax.annotate(labels[i], (x[i], y[i]), color='b')\n","\n","            for i in range(points_2d.shape[0]):\n","                ax.annotate(labels_posit[i], (points_2d[:, 0][i], points_2d[:, 1][i]), color='r')\n","\n","        # применяем ко всем шлемам Posit\n","        points_2d_full = np.array([out_posit['x'].values, 720-out_posit['y'].values]).transpose()\n","        points_3d_full = np.array([tracking_posit['x'].values, tracking_posit['y'].values]).transpose()\n","        points_3d_full = np.append(points_3d_full, np.zeros((points_3d_full.shape[0], 1)), axis=1)\n","\n","        projected_points_2d_full = np.matmul(full_matrix, np.transpose(np.append(points_3d_full, np.ones((points_3d_full.shape[0], 1)), axis=1)))\n","        projected_points_2d_t_full = np.transpose(projected_points_2d_full)\n","        projected_points_2d_homogen_full = projected_points_2d_t_full / projected_points_2d_full[2].reshape(points_3d_full.shape[0],1)\n","        tracking_posit[\"x_pr\"] = projected_points_2d_homogen_full[:, 0]\n","        tracking_posit[\"y_pr\"] = projected_points_2d_homogen_full[:, 1]\n","\n","        # Отрисовываем все шлемы\n","        if PLOT:\n","            figure(figsize=(10,10))\n","            plt.plot(points_2d_full[:, 0], points_2d_full[:, 1], 'rx')\n","            plt.plot(projected_points_2d_homogen_full[:, 0], projected_points_2d_homogen_full[:, 1], 'b.')\n","            plt.axis('scaled')\n","            plt.show()\n","\n","            x = projected_points_2d_homogen_full[:, 0]\n","            y = projected_points_2d_homogen_full[:, 1]\n","            labels = tracking_posit['player'].values\n","            labels_posit = out_posit['label'].values\n","            fig, ax = plt.subplots()\n","            ax.axis('equal')\n","\n","            fig.set_size_inches((30, 30))\n","            ax.scatter(points_2d_full[:, 0], points_2d_full[:, 1], marker='x', color='r')\n","            ax.scatter(x, y, marker='.', color='b')\n","            for i in range(len(x)):\n","                ax.annotate(labels[i], (x[i], y[i]), color='b')\n","\n","            for i in range(len(labels_posit)):\n","                ax.annotate(labels_posit[i], (points_2d_full[:, 0][i], points_2d_full[:, 1][i]), color='r')\n","\n","\n","        out_posit['label_posit'] = out_posit['label_deepsort'].values.copy()\n","        out_posit['y_im'] = (720 - out_posit['y']).copy()\n","        indexes_to_all_distances ={}\n","        for index, row in out_posit.iterrows():\n","            all_distances = np.sqrt(np.square(tracking_posit['x_pr'].values - row['x']) + np.square(tracking_posit['y_pr'].values - row['y_im']))\n","            all_labels = tracking_posit['player'].values \n","            indexes_to_all_distances[index] = sorted(list(zip(all_labels, all_distances)), key=lambda tup: tup[1])\n","\n","\n","        all_results = {}\n","        expected_num_of_results = len(indexes_to_all_distances)\n","        for _ in range(expected_num_of_results):\n","            min_element = None\n","            min_dist = float('inf')\n","            min_label = None\n","            for k, v in indexes_to_all_distances.items():\n","                if v[0][1] < min_dist:\n","                    min_dist = v[0][1]\n","                    min_element = k\n","                    min_label = v[0][0]\n","            if min_element:\n","                all_results[min_element] = min_label\n","            indexes_to_all_distances.pop(min_element, None)\n","            for k, v in indexes_to_all_distances.items():\n","                indexes_to_all_distances[k] = [t for t in v if t[0] != min_label]\n","\n","        for k, v in all_results.items():\n","            out_posit.loc[k,'label_posit'] = v\n","\n","        outs_posit.append(out_posit.copy())\n","\n","    submission_posit = pd.concat(outs_posit).copy()\n","    return submission_posit"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:07:25.554463Z","iopub.execute_input":"2021-10-01T10:07:25.554864Z","iopub.status.idle":"2021-10-01T10:07:25.629927Z","shell.execute_reply.started":"2021-10-01T10:07:25.554808Z","shell.execute_reply":"2021-10-01T10:07:25.628478Z"},"trusted":true}},{"cell_type":"code","execution_count":20,"source":["# Add video and frame columns to submission.\n","submission_df['video'] = submission_df['video_frame'].str.split('_').str[:3].str.join('_')\n","submission_df['frame'] = submission_df['video_frame'].str.split('_').str[-1].astype('int')\n","\n","if debug:\n","    video_dir = f'{ENTRY}/nfl-health-and-safety-helmet-assignment/train/'\n","else:\n","    video_dir = f'{ENTRY}/nfl-health-and-safety-helmet-assignment/test/'\n","\n","submission_df_small = submission_df.loc[submission_df['frame']<51].copy()\n","submission_df_small.frame.unique()"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,  2, 20, 21, 22, 23, 24,\n","       25, 26, 27, 28, 29,  3, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,  4,\n","       40, 41, 42, 43, 44, 45, 46, 47, 48, 49,  5, 50,  6,  7,  8,  9])"]},"metadata":{},"execution_count":20}],"metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-01T10:07:25.633018Z","iopub.execute_input":"2021-10-01T10:07:25.633416Z","iopub.status.idle":"2021-10-01T10:07:25.729998Z","shell.execute_reply.started":"2021-10-01T10:07:25.633380Z","shell.execute_reply":"2021-10-01T10:07:25.728745Z"},"trusted":true}},{"cell_type":"code","execution_count":10,"source":["# ОПТИМИЗАЦИЯ 127 seconds -> 124 second\n","#     track_confidence = {}\n","#     for cluster in out['deepsort_cluster'].unique(): # Пробегаемся по кластерам дипсорта\n","#         if not np.isnan(cluster): # Если кластер не None, то есть после пропускаемых дипсортом кадров\n","#             label_count = out[out['deepsort_cluster'] == cluster]['label_count_deepsort'].unique()[0] # количество появлений топ кластера\n","#             num_frames = len(out[out['deepsort_cluster'] == cluster]) # число кадров\n","# #             print(cluster, 'label_count',label_count,'num_frames',num_frames)\n","#             track_confidence[cluster] = label_count/num_frames # как часто кластер появляется на кадре. Словарь Кластер:Частота\n","# #     print('track_confidence\\n',track_confidence)\n","# replace to this \n","# count_clusters = out.groupby(['deepsort_cluster','label'], as_index=False).count()\n","# track_confidence = (count_clusters.groupby(['deepsort_cluster']).max().video_frame / count_clusters.groupby(['deepsort_cluster']).sum().video_frame).to_dict()"],"outputs":[],"metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-01T10:07:25.731677Z","iopub.execute_input":"2021-10-01T10:07:25.732013Z","iopub.status.idle":"2021-10-01T10:07:25.737062Z","shell.execute_reply.started":"2021-10-01T10:07:25.731980Z","shell.execute_reply":"2021-10-01T10:07:25.735848Z"},"trusted":true}},{"cell_type":"code","execution_count":21,"source":["# Loop through test videos and apply. If in debug mode show the score change.\n","outs = []\n","outs_posit = []\n","for myvideo, video_data in tqdm(submission_df_small.groupby('video'), total=submission_df['video'].nunique()):\n","    print(f'==== {myvideo} ====')\n","    if debug:\n","        # Plot deepsort labels when in debug mode.\n","        out = deepsort_helmets(video_data, video_dir, plot_frames=range(3,100,10)) #i for i in range(0,1000,20)] + [379, 381]\n","        # print(out)\n","    else:\n","        out = deepsort_helmets(video_data, video_dir)      \n","    # Находим лэйбл, который в наибольшем количестве кадров присутствовал с определенным кластером. Добавляются label_deepsort (ИД игрока) label_count_deepsort (число)\n","    out = add_deepsort_label_col(out) \n","    outs.append(out) # итоговые датафреймы складываются в список\n","    #####\n","    tracking_gp = tracking[tracking['game_play'] == '_'.join((myvideo.split('_'))[:-1])].copy() # просто трек текущего видео\n","    out_posit = process_with_posit(out, tracking_gp) # Posit\n","    outs_posit.append(out_posit)\n","    #####\n","    if debug:\n","        score_vs_deepsort(myvideo, out, labels)\n","        score_vs_posit(myvideo, out_posit, labels) #\n","        \n","submission_deepsort = pd.concat(outs).copy()\n","submission_posit = pd.concat(outs_posit).copy()\n","# ==== 57783_003374_Endzone ====\n","# 0.27200 before --> 0.63371 deepsort --> 0.67545 posit\n","# ==== 57783_003374_Sideline ====\n","# 0.29314 before --> 0.32986 deepsort --> 0.60836 posit\n","\n","# ==== 57783_003374_Endzone ==== 50 frames\n","# 0.09549 before --> 0.30871 deepsort --> 0.31109 posit\n","# ==== 57783_003374_Sideline ==== 50 frames\n","# 0.09459 before --> 0.05549 deepsort --> 0.01022 posit\n","# 127 seconds -> 124 seconds"],"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/2 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["==== 57783_003374_Endzone ====\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [00:52<00:00,  1.05s/it]\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:77: RuntimeWarning: divide by zero encountered in double_scalars\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:79: RuntimeWarning: divide by zero encountered in double_scalars\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:84: RuntimeWarning: invalid value encountered in multiply\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:85: RuntimeWarning: invalid value encountered in multiply\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:95: RuntimeWarning: invalid value encountered in true_divide\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:77: RuntimeWarning: divide by zero encountered in double_scalars\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:79: RuntimeWarning: divide by zero encountered in double_scalars\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:84: RuntimeWarning: invalid value encountered in multiply\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:85: RuntimeWarning: invalid value encountered in multiply\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:95: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["(827, 14)\n","(787, 14)\n","0.09549 before --> 0.30871 deepsort\n","(827, 16)\n","(795, 16)\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 1/2 [00:53<00:53, 53.84s/it]"]},{"output_type":"stream","name":"stdout","text":["0.09549 before --> 0.31109 posit\n","==== 57783_003374_Sideline ====\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 50/50 [01:09<00:00,  1.38s/it]\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:77: RuntimeWarning: divide by zero encountered in double_scalars\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:79: RuntimeWarning: divide by zero encountered in double_scalars\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:84: RuntimeWarning: invalid value encountered in multiply\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:85: RuntimeWarning: invalid value encountered in multiply\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:95: RuntimeWarning: invalid value encountered in true_divide\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:77: RuntimeWarning: divide by zero encountered in double_scalars\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:79: RuntimeWarning: divide by zero encountered in double_scalars\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:84: RuntimeWarning: invalid value encountered in multiply\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:85: RuntimeWarning: invalid value encountered in multiply\n","/Users/apple/opt/anaconda3/envs/Py37/lib/python3.7/site-packages/ipykernel_launcher.py:95: RuntimeWarning: invalid value encountered in true_divide\n"]},{"output_type":"stream","name":"stdout","text":["(1085, 14)\n","(857, 14)\n","0.09459 before --> 0.05549 deepsort\n","(1085, 16)\n","(1041, 16)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2/2 [02:04<00:00, 62.07s/it]"]},{"output_type":"stream","name":"stdout","text":["0.09459 before --> 0.01022 posit\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2021-10-01T10:07:25.738736Z","iopub.execute_input":"2021-10-01T10:07:25.739184Z","iopub.status.idle":"2021-10-01T10:09:01.807048Z","shell.execute_reply.started":"2021-10-01T10:07:25.739147Z","shell.execute_reply":"2021-10-01T10:09:01.805383Z"},"trusted":true}},{"cell_type":"code","execution_count":12,"source":["# # for tester\n","# out.to_csv('tstr/out.csv')\n","# tracking_gp.to_csv('tstr/tracking_gp.csv')"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["# Check Submission & Save\n","Finally we will create a submission file and check that it passes the submission requirements.\n","The steps are:\n","1. Drop the `label` and replace with `label_deepsort` predictions.\n","2. Remove any duplicate labels within a single video/frame. This is required to meet the submission requirements.\n","3. Save the results."],"metadata":{}},{"cell_type":"code","execution_count":14,"source":["# Deepsort Submission\n","ss = pd.read_csv(f'{ENTRY}/nfl-health-and-safety-helmet-assignment/sample_submission.csv')\n","# Final Checks\n","submission_deepsort['label_deepsort'] = submission_deepsort['label_deepsort'].fillna(submission_deepsort['label'])\n","submission_posit['label_posit'] = submission_posit['label_posit'].fillna(submission_posit['label'])\n","\n","submission_deepsort = submission_deepsort.drop('label', axis=1).rename(columns={'label_deepsort':'label'})[ss.columns]\n","submission_posit = submission_posit.drop('label', axis=1).rename(columns={'label_posit':'label'})[ss.columns]\n","# Drop duplicate labels\n","submission_deepsort = submission_deepsort.loc[~submission_deepsort[['video_frame','label']].duplicated()]\n","submission_posit = submission_posit.loc[~submission_posit[['video_frame','label']].duplicated()]\n","\n","check_submission(submission_deepsort)\n","check_submission(submission_posit)\n","\n","# submission_deepsort.to_csv('submission.csv', index=False)\n","submission_posit.to_csv('submission.csv', index=False)"],"outputs":[],"metadata":{"execution":{"iopub.status.busy":"2021-10-01T10:09:02.115969Z","iopub.status.idle":"2021-10-01T10:09:02.116980Z"},"trusted":true}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{"trusted":true}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}},{"cell_type":"code","execution_count":null,"source":[],"outputs":[],"metadata":{}}]}